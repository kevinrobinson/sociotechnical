# Meta
## Framing for reading and critiquing

This has to speak to two audiences well, and here are some of my core assumptions that influenced decisions below.  These are of course assumptions and huge generalizations and I hope they are only as useful as communicating the flavor of what I mean :)

One audience is people doing things like attending FaCCT, listening to the Radical AI podcast, reading Design Justice, sharing AI Now papers, and building out governance models for large organizations like ABOUT ML.  It's most of the people involved in this project right now, and it's the people that will grow it in the early phase.  That audience is the heart and core of this work - it has to feel good about this project, and it has a lot of veto power it can use.  But it is not the primary audience.

The primary audience is people who do not particularly care about fairness.  They are data scientists or software engineers.  Maybe someday they'll also be designers and product managers, but not yet.  This is the site that someone who cares deeply about fairness can email to another engineer and say "let's pick something to try from what's here."

This audience is a maybe even a little bit skeptical of fairness broadly.  They've seen [will.i.am](https://twitter.com/iamwill/status/1220031430799101953) doing corporate press releases, and they've maybe heard a mash of the different phrases and brandings different groups use to differentiate themselves, like ethical AI responsible AI fair AI transparent AI human-centered AI interpretable AI explainable AI intelligible AI accountable AI.  They do not want a [Venn diagram](https://www.h2o.ai/blog/brief-perspective-on-key-terms-and-ideas-in-responsible-ai-2/) describing these terms.  None of that seems like is is speaking to them.

They're in industry more than academia.  Research papers signal that the project is not for them.  They might use Twitter but are less likely to use Twitter chats and hashtags.  They are open to epistimelogical pluralism, but not if we call it that :)

This audience has a shorter time horizon.  That's where some of the emphasis on "move quickly" that you'll see here comes from, but of course this is a strategy to grow the top of the funnel and reach more people, with the hope that we'll provide more value than that over time.

Also, some of the tone choices here are an attempt to signal that this site is for data scientists and engineers, not for academics and not for corporate compliance.  The challenge is doing that in a way that feels right to the secondary audience who cares deeply about fairness as a sociotechnical challenge, and may react quite strongly to any hint of techno-solutionism or amateurism or lack of professional responsibility that seems like it's being endorsed.  I think of Hanna talking about being concerned that there even is a software project, and how critically important language and word choice is.

Here's an attempt to empathize with and speak to both audiences.

## Theory of change
The theory of change here is similar to take ideas at the heart of communities like FAccT, and do the translational work to reach a broader audience of developers.  This translationa work is key, because:

> All too often, the data scientists we have encountered are quite sympathetic to the sentiment behind the critiques they hear, but feel maligned and misunderstood, unacknowledged for their efforts, and frustrated by vague recommendations that are not actionable... The gaps between data scientists and critics are wide, but critique divorced from practice only increases them. Data scientists, as the ones closest to the work, are often the best positioned to address ethical concerns, but they often need help from those who are willing to take time to understand what they are doing and the challenges of their practice.
- [Barocas and Boyd (2017)](https://cacm.acm.org/magazines/2017/11/222176-engaging-the-ethics-of-data-science-in-practice/fulltext)

Another way to think of this project is: taking ML fairness research, and work on justice equity and power more broadly, and making it accessible to developers and data scientists.  This is similar to a literature review, or a policy report, but in a medium for developers.  A primary part of this work is accepting responsibility for what practioners need:

> But the reality is that data scientists still lack the methodological tools necessary to critically engage with the epistemological and normative aspects of their work.
- [Barbaras et al. (2020)](https://dl.acm.org/doi/pdf/10.1145/3351095.3372859)

And also that data scientists are often engaged and included in projects precisely because of the ideology and practices that are common in the field:

> [data science] is characterized by extremely asymmetrical power relations, wherethose with power and privilege are the only ones who can actuallycollect the data but they have overwhelming incentives to ignorethe problem, precisely because addressing it poses a threat to their dominance
- [Dâ€™Ignazio and Klein (2019)](https://mitpress.mit.edu/books/data-feminism)

This means that any educational work must acknowledge the tension in these goals: aspirations to "do better," disciplinary ideologies and practices in tension with "doing better," and structural pressures against "doing better."
