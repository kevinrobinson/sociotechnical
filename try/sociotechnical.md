# Adding sociotechnical context

## Understanding sociotechnical context can dramatically improve estimates of a system's performance
Humans alter their behavior when ML systems are deployed, but not always in the ways that data scientists or ML teams predict ([De-Arteaga et al. 2020](https://arxiv.org/pdf/2002.08035.pdf)).

Even adding visualizations about model performance can lead users to  misuse the system ([Kaur et al. 2020](http://www.jennwv.com/papers/interp-ds.pdf)).

And people are "less likely to adhere to the machineâ€™s recommendation when the score displayed was an incorrect estimate of risk" ([Fogliato et al. 2020](https://www.dropbox.com/s/kyk1067yk6a6yqp/Lessons_from_the_Deployment_of_an_Algorithmic_Tool_in_Child_Welfare.pdf?dl=0)).

Sometimes this can even contribute to a "general distrust in the existing system [that] contributes significantly to low comfort in algorithmic decision making" ([Brown et al. 2019](https://www.andrew.cmu.edu/user/achoulde/files/accountability_final_balanced.pdf)).
